{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OKOMKAMARA/Dart-Project/blob/main/AIPND_image_classifier_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code Explanation:\n",
        "\n",
        "- **Setting Up Flower Dataset:**\n",
        "  - `data_dir = './flowers'`: Defines the directory path for the flower dataset.\n",
        "  - `FLOWERS_DIR = Path(data_dir)`: Uses `Path` from `pathlib` for handling PosixPath.\n",
        "\n",
        "- **Downloading and Extracting Dataset:**\n",
        "  - `if not FLOWERS_DIR.is_dir()`: Checks if the dataset directory exists.\n",
        "    - `FLOWERS_DIR.mkdir(parents=True, exist_ok=True)`: Creates the directory if not present.\n",
        "  - `TARBALL = FLOWERS_DIR / \"flower_data.tar.gz\"`: Defines the tarball path.\n",
        "  - Downloads and extracts the dataset if not already present:\n",
        "    - `request = requests.get(...)`: Downloads the 'flower_data.tar.gz' file.\n",
        "    - `with open(TARBALL, \"wb\") as file_ref`: Writes the downloaded content to the tarball.\n",
        "    - `with tarfile.open(TARBALL, \"r\") as tar_ref`: Extracts the tarball contents to the dataset directory.\n",
        "\n",
        "- **Cleaning Up:**\n",
        "  - `os.remove(TARBALL)`: Deletes the downloaded tarball to save space.\n",
        "\n",
        "- **Status Messages:**\n",
        "  - Prints informative messages about the directory creation, download, extraction, and cleanup.\n"
      ],
      "metadata": {
        "id": "3EUKirN80Na6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RFHu1nUUE_PF",
        "outputId": "ae49dbcc-ca49-463d-80fa-a4d5b09d61f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Dataset already setup at ./flowers\n"
          ]
        }
      ],
      "source": [
        "# imports\n",
        "import os\n",
        "import requests\n",
        "from pathlib import Path\n",
        "import tarfile\n",
        "\n",
        "# defining dataset directory\n",
        "data_dir = './flowers'\n",
        "\n",
        "# using pathlib.Path for handling PosixPath\n",
        "FLOWERS_DIR = Path(data_dir)\n",
        "\n",
        "# downloading and setting up data if not already present\n",
        "if not FLOWERS_DIR.is_dir():\n",
        "    # creating directory\n",
        "    FLOWERS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"[INFO] Directory created: ./{FLOWERS_DIR}\")\n",
        "\n",
        "    print() # for readability\n",
        "\n",
        "    # tarball path\n",
        "    TARBALL = FLOWERS_DIR / \"flower_data.tar.gz\"\n",
        "\n",
        "    # downloading and writing the tarball to './flowers' directory\n",
        "    print(f\"[INFO] Downloading the file 'flower_data.tar.gz' to ./{FLOWERS_DIR}\")\n",
        "    request = requests.get('https://s3.amazonaws.com/content.udacity-data.com/nd089/flower_data.tar.gz')\n",
        "    with open(TARBALL, \"wb\") as file_ref:\n",
        "        file_ref.write(request.content)\n",
        "        print(f\"[INFO] 'flower_data.tar.gz' saved to ./{FLOWERS_DIR}\")\n",
        "\n",
        "    print() # for readability\n",
        "\n",
        "    # extracting the downloaded tarball\n",
        "    print(f\"[INFO] Extracting the downloaded tarball to ./{FLOWERS_DIR}\")\n",
        "    with tarfile.open(TARBALL, \"r\") as tar_ref:\n",
        "        tar_ref.extractall(FLOWERS_DIR)\n",
        "        print(f\"[INFO] 'flower_data.tar.gz' extracted successfully to ./{FLOWERS_DIR}\")\n",
        "\n",
        "    print() # for readability\n",
        "\n",
        "    # using os.remove to delete the downloaded tarball\n",
        "    print(\"[INFO] Deleting the tarball to save space.\")\n",
        "    os.remove(TARBALL)\n",
        "else:\n",
        "    print(f\"[INFO] Dataset already setup at ./{FLOWERS_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code Explanation:\n",
        "\n",
        "- **Creating a JSON File for Flower Categories:**\n",
        "  - `data`: Defines a dictionary containing numerical keys and corresponding flower names.\n",
        "  - `with open('cat_to_name.json', 'w') as file`: Opens the file 'cat_to_name.json' for writing.\n",
        "  - `json.dump(data, file)`: Writes the dictionary data to the JSON file.\n",
        "\n",
        "- **Interpreting the Output:**\n",
        "  - The code creates a JSON file named 'cat_to_name.json' that serves as a mapping between numerical keys and flower names. This mapping can be useful for associating numerical labels with human-readable names in machine learning tasks.\n"
      ],
      "metadata": {
        "id": "CsRLKv2u0ard"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "data = {\n",
        "    \"21\": \"fire lily\", \"3\": \"canterbury bells\", \"45\": \"bolero deep blue\", \"1\": \"pink primrose\", \"34\": \"mexican aster\",\n",
        "    \"27\": \"prince of wales feathers\", \"7\": \"moon orchid\", \"16\": \"globe-flower\", \"25\": \"grape hyacinth\", \"26\": \"corn poppy\",\n",
        "    \"79\": \"toad lily\", \"39\": \"siam tulip\", \"24\": \"red ginger\", \"67\": \"spring crocus\", \"35\": \"alpine sea holly\",\n",
        "    \"32\": \"garden phlox\", \"10\": \"globe thistle\", \"6\": \"tiger lily\", \"93\": \"ball moss\", \"33\": \"love in the mist\",\n",
        "    \"9\": \"monkshood\", \"102\": \"blackberry lily\", \"14\": \"spear thistle\", \"19\": \"balloon flower\", \"100\": \"blanket flower\",\n",
        "    \"13\": \"king protea\", \"49\": \"oxeye daisy\", \"15\": \"yellow iris\", \"61\": \"cautleya spicata\", \"31\": \"carnation\",\n",
        "    \"64\": \"silverbush\", \"68\": \"bearded iris\", \"63\": \"black-eyed susan\", \"69\": \"windflower\", \"62\": \"japanese anemone\",\n",
        "    \"20\": \"giant white arum lily\", \"38\": \"great masterwort\", \"4\": \"sweet pea\", \"86\": \"tree mallow\",\n",
        "    \"101\": \"trumpet creeper\", \"42\": \"daffodil\", \"22\": \"pincushion flower\", \"2\": \"hard-leaved pocket orchid\",\n",
        "    \"54\": \"sunflower\", \"66\": \"osteospermum\", \"70\": \"tree poppy\", \"85\": \"desert-rose\", \"99\": \"bromelia\", \"87\": \"magnolia\",\n",
        "    \"5\": \"english marigold\", \"92\": \"bee balm\", \"28\": \"stemless gentian\", \"97\": \"mallow\", \"57\": \"gaura\",\n",
        "    \"40\": \"lenten rose\", \"47\": \"marigold\", \"59\": \"orange dahlia\", \"48\": \"buttercup\", \"55\": \"pelargonium\",\n",
        "    \"36\": \"ruby-lipped cattleya\", \"91\": \"hippeastrum\", \"29\": \"artichoke\", \"71\": \"gazania\", \"90\": \"canna lily\",\n",
        "    \"18\": \"peruvian lily\", \"98\": \"mexican petunia\", \"8\": \"bird of paradise\", \"30\": \"sweet william\",\n",
        "    \"17\": \"purple coneflower\", \"52\": \"wild pansy\", \"84\": \"columbine\", \"12\": \"colt's foot\", \"11\": \"snapdragon\",\n",
        "    \"96\": \"camellia\", \"23\": \"fritillary\", \"50\": \"common dandelion\", \"44\": \"poinsettia\", \"53\": \"primula\",\n",
        "    \"72\": \"azalea\", \"65\": \"californian poppy\", \"80\": \"anthurium\", \"76\": \"morning glory\", \"37\": \"cape flower\",\n",
        "    \"56\": \"bishop of llandaff\", \"60\": \"pink-yellow dahlia\", \"82\": \"clematis\", \"58\": \"geranium\", \"75\": \"thorn apple\",\n",
        "    \"41\": \"barbeton daisy\", \"95\": \"bougainvillea\", \"43\": \"sword lily\", \"83\": \"hibiscus\", \"78\": \"lotus lotus\",\n",
        "    \"88\": \"cyclamen\", \"94\": \"foxglove\", \"81\": \"frangipani\", \"74\": \"rose\", \"89\": \"watercress\", \"73\": \"water lily\",\n",
        "    \"46\": \"wallflower\", \"77\": \"passion flower\", \"51\": \"petunia\"\n",
        "}\n",
        "\n",
        "with open('cat_to_name.json', 'w') as file:\n",
        "    json.dump(data, file)"
      ],
      "metadata": {
        "id": "m6378UAqFK_t"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports here\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FormatStrFormatter\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "import json\n",
        "from collections import OrderedDict\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "TXp5ykr-TQLC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'flowers'\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir = data_dir + '/valid'\n",
        "test_dir = data_dir + '/test'"
      ],
      "metadata": {
        "id": "idR1X_MpUThN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Define your transforms for the training, validation, and testing sets\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                     transforms.RandomResizedCrop(224),\n",
        "                                     transforms.RandomHorizontalFlip(),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                         [0.229, 0.224, 0.225])\n",
        "                                     ])\n",
        "\n",
        "validation_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                    transforms.CenterCrop(224),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                        [0.229, 0.224, 0.225])\n",
        "                                     ])\n",
        "test_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                    transforms.CenterCrop(224),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                       [0.229, 0.224, 0.225])\n",
        "                                      ])\n",
        "\n",
        "\n",
        "\n",
        "# TODO: Load the datasets with ImageFolder\n",
        "image_datasets = [datasets.ImageFolder(train_dir, transform = train_transforms),\n",
        "                 datasets.ImageFolder(valid_dir, transform = validation_transforms),\n",
        "                 datasets.ImageFolder(test_dir, transform = test_transforms)]\n",
        "\n",
        "\n",
        "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
        "dataloaders = [torch.utils.data.DataLoader(image_datasets[0], batch_size = 64, shuffle = True),\n",
        "              torch.utils.data.DataLoader(image_datasets[1], batch_size = 64),\n",
        "              torch.utils.data.DataLoader(image_datasets[2], batch_size = 64)]"
      ],
      "metadata": {
        "id": "JK65kczaUVZ1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('cat_to_name.json', 'r') as f:\n",
        "    cat_to_name = json.load(f)"
      ],
      "metadata": {
        "id": "Y4OMMkM-Udkx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Build and train your network\n",
        "\n",
        "# Use GPU if it's available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "# Load the pre-trained network VGG16\n",
        "model = models.vgg16(pretrained = True)\n",
        "\n",
        "model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cSErhwR7UhNW",
        "outputId": "96f0d0c6-c2a3-4446-96a6-ba2ac03df5fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:06<00:00, 79.3MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a new, untrained feed-forward network as a classifier, using RElU activations and dropout\n",
        "\n",
        "# Freeze parameters so we don't backprop through them\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Define the new classifier for the model\n",
        "\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "    ('fc1', nn.Linear(20, 256)),\n",
        "    ('relu', nn.ReLU()),\n",
        "    ('dropout', nn.Dropout(0.5)),\n",
        "#     ('fc2', nn.Linear(4096, 512)),\n",
        "#     ('relu', nn.ReLU()),\n",
        "    ('fc3', nn.Linear(256, 102)),\n",
        "    ('output', nn.LogSoftmax(dim = 1))\n",
        "]))\n",
        "\n",
        "# Update the classifier in the model\n",
        "model.classifier = classifier\n",
        "\n",
        "model"
      ],
      "metadata": {
        "id": "LS0Tj_DkVZaX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}